{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-07-09T12:24:32.214697Z",
     "iopub.execute_input": "2022-07-09T12:24:32.215240Z",
     "iopub.status.idle": "2022-07-09T12:24:32.270060Z",
     "shell.execute_reply.started": "2022-07-09T12:24:32.215127Z",
     "shell.execute_reply": "2022-07-09T12:24:32.269184Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data and label"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "tweets = []\n",
    "labels = []\n",
    "\n",
    "def load_tweets(filename, label):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tweets.append(line.rstrip())\n",
    "            labels.append(label)\n",
    "    \n",
    "load_tweets('../input/cil-twitter/twitter-datasets/train_neg_full.txt', 0)\n",
    "load_tweets('../input/cil-twitter/twitter-datasets/train_pos_full.txt', 1)\n",
    "\n",
    "# Convert to NumPy array to facilitate indexing\n",
    "tweets = np.array(tweets)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f'{len(tweets)} tweets loaded')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T12:24:35.488341Z",
     "iopub.execute_input": "2022-07-09T12:24:35.489322Z",
     "iopub.status.idle": "2022-07-09T12:24:41.835397Z",
     "shell.execute_reply.started": "2022-07-09T12:24:35.489275Z",
     "shell.execute_reply": "2022-07-09T12:24:41.834393Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build validation set\n",
    "We use 90% of tweets for training, and 10% for validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(1) # Reproducibility!\n",
    "\n",
    "shuffled_indices = np.random.permutation(len(tweets))\n",
    "split_idx = int(0.9 * len(tweets))\n",
    "train_indices = shuffled_indices[:split_idx]\n",
    "val_indices = shuffled_indices[split_idx:]\n",
    "\n",
    "len(train_indices), len(val_indices)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T12:24:45.407066Z",
     "iopub.execute_input": "2022-07-09T12:24:45.407444Z",
     "iopub.status.idle": "2022-07-09T12:24:45.472597Z",
     "shell.execute_reply.started": "2022-07-09T12:24:45.407410Z",
     "shell.execute_reply": "2022-07-09T12:24:45.471659Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T12:24:50.036583Z",
     "iopub.execute_input": "2022-07-09T12:24:50.037309Z",
     "iopub.status.idle": "2022-07-09T12:24:55.507815Z",
     "shell.execute_reply.started": "2022-07-09T12:24:50.037277Z",
     "shell.execute_reply": "2022-07-09T12:24:55.507005Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BERT Tokenizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T12:25:00.889110Z",
     "iopub.execute_input": "2022-07-09T12:25:00.889736Z",
     "iopub.status.idle": "2022-07-09T12:25:11.709919Z",
     "shell.execute_reply.started": "2022-07-09T12:25:00.889702Z",
     "shell.execute_reply": "2022-07-09T12:25:11.708910Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import transformers\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T12:25:11.711859Z",
     "iopub.execute_input": "2022-07-09T12:25:11.712247Z",
     "iopub.status.idle": "2022-07-09T12:25:13.820305Z",
     "shell.execute_reply.started": "2022-07-09T12:25:11.712206Z",
     "shell.execute_reply": "2022-07-09T12:25:13.819523Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BERT Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def create_bert_input_features(tokenizer, docs, max_seq_length):\n",
    "    \n",
    "    all_ids, all_masks = [], []\n",
    "    for doc in tqdm.tqdm(docs, desc=\"Converting docs to features\"):\n",
    "        \n",
    "        tokens = tokenizer.tokenize(doc)\n",
    "        \n",
    "        if len(tokens) > max_seq_length-2:\n",
    "            tokens = tokens[0 : (max_seq_length-2)]\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        masks = [1] * len(ids)\n",
    "        \n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(ids) < max_seq_length:\n",
    "            ids.append(0)\n",
    "            masks.append(0)\n",
    "            \n",
    "        all_ids.append(ids)\n",
    "        all_masks.append(masks)\n",
    "        \n",
    "    encoded = np.array([all_ids, all_masks])\n",
    "    \n",
    "    return encoded"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T12:25:23.558850Z",
     "iopub.execute_input": "2022-07-09T12:25:23.559315Z",
     "iopub.status.idle": "2022-07-09T12:25:23.572841Z",
     "shell.execute_reply.started": "2022-07-09T12:25:23.559271Z",
     "shell.execute_reply": "2022-07-09T12:25:23.570988Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Model Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "MAX_SEQ_LENGTH = 70\n",
    "\n",
    "inp_id = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_ids\")\n",
    "inp_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_masks\")\n",
    "inputs = [inp_id, inp_mask]\n",
    "\n",
    "hidden_state = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')(inputs)[0]\n",
    "pooled_output = hidden_state[:, 0]    \n",
    "\n",
    "dense1 = tf.keras.layers.Dense(256, activation='relu')(pooled_output)\n",
    "drop1 = tf.keras.layers.Dropout(0.25)(dense1)\n",
    "dense2 = tf.keras.layers.Dense(256, activation='relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(0.25)(dense2)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=2e-5,  #2e-5\n",
    "                                           epsilon=1e-08), \n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T12:25:28.368025Z",
     "iopub.execute_input": "2022-07-09T12:25:28.368478Z",
     "iopub.status.idle": "2022-07-09T12:25:54.352395Z",
     "shell.execute_reply.started": "2022-07-09T12:25:28.368438Z",
     "shell.execute_reply": "2022-07-09T12:25:54.351590Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bert tokenizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer_tweet = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T12:25:54.354105Z",
     "iopub.execute_input": "2022-07-09T12:25:54.354853Z",
     "iopub.status.idle": "2022-07-09T12:26:00.671074Z",
     "shell.execute_reply.started": "2022-07-09T12:25:54.354814Z",
     "shell.execute_reply": "2022-07-09T12:26:00.670215Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_features_ids, train_features_masks = create_bert_input_features(tokenizer_tweet, tweets[train_indices][0:1000000],    \n",
    "                                                                      max_seq_length=MAX_SEQ_LENGTH)  "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-09T12:26:30.588716Z",
     "iopub.execute_input": "2022-07-09T12:26:30.589389Z",
     "iopub.status.idle": "2022-07-09T12:29:36.873170Z",
     "shell.execute_reply.started": "2022-07-09T12:26:30.589333Z",
     "shell.execute_reply": "2022-07-09T12:29:36.872132Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "MAX_SEQ_LENGTH = 70\n",
    "\n",
    "inp_id = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_ids\")\n",
    "inp_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_masks\")\n",
    "inputs = [inp_id, inp_mask]\n",
    "\n",
    "hidden_state = transformers.TFRobertaModel.from_pretrained(\"vinai/bertweet-base\")(inputs)[0]\n",
    "\n",
    "\n",
    "\n",
    "pooled_output = hidden_state[:, 0]    \n",
    "\n",
    "dense1 = tf.keras.layers.Dense(256, activation='relu')(pooled_output)\n",
    "drop1 = tf.keras.layers.Dropout(0.25)(dense1)\n",
    "dense2 = tf.keras.layers.Dense(256, activation='relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(0.25)(dense2)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=2e-5,  #2e-5\n",
    "                                           epsilon=1e-08), \n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T13:58:04.702863Z",
     "iopub.execute_input": "2022-07-03T13:58:04.703315Z",
     "iopub.status.idle": "2022-07-03T13:58:35.431128Z",
     "shell.execute_reply.started": "2022-07-03T13:58:04.703267Z",
     "shell.execute_reply": "2022-07-03T13:58:35.430314Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Y_train = labels[train_indices]\n",
    "Y_val = labels[val_indices]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T13:58:35.432576Z",
     "iopub.execute_input": "2022-07-03T13:58:35.433286Z",
     "iopub.status.idle": "2022-07-03T13:58:35.461266Z",
     "shell.execute_reply.started": "2022-07-03T13:58:35.433238Z",
     "shell.execute_reply": "2022-07-03T13:58:35.460425Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "val_features_ids, val_features_masks = create_bert_input_features(tokenizer_tweet, tweets[val_indices], \n",
    "                                                                  max_seq_length=MAX_SEQ_LENGTH)\n",
    "                                                                  \n",
    "                                                                  \n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=1,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)         "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T13:58:35.463534Z",
     "iopub.execute_input": "2022-07-03T13:58:35.463953Z",
     "iopub.status.idle": "2022-07-03T13:59:20.611199Z",
     "shell.execute_reply.started": "2022-07-03T13:58:35.463915Z",
     "shell.execute_reply": "2022-07-03T13:59:20.610345Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit([train_features_ids, \n",
    "           train_features_masks], Y_train[0:1000000], \n",
    "          validation_data=([val_features_ids, \n",
    "                            val_features_masks], Y_val),\n",
    "          epochs=2, \n",
    "          batch_size=130, \n",
    "          shuffle=True,\n",
    "          callbacks=[es],\n",
    "          verbose=1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T14:01:03.979018Z",
     "iopub.execute_input": "2022-07-03T14:01:03.979364Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.save_weights(\"bertweet_1.h5\")\n",
    "model.load_weights(\"bertweet_1.h5\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-02T20:23:28.164376Z",
     "iopub.execute_input": "2022-07-02T20:23:28.164772Z",
     "iopub.status.idle": "2022-07-02T20:23:29.742516Z",
     "shell.execute_reply.started": "2022-07-02T20:23:28.164738Z",
     "shell.execute_reply": "2022-07-02T20:23:29.741546Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning for RAM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import gc\n",
    "del train_features_ids, train_features_masks\n",
    "gc.collect()"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.load_weights(\"bertweet_1.h5\")\n",
    "\n",
    "train_features_ids, train_features_masks = create_bert_input_features(tokenizer_tweet, tweets[train_indices][1000000:],    \n",
    "                                                                      max_seq_length=MAX_SEQ_LENGTH)  "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-02T20:26:17.725505Z",
     "iopub.execute_input": "2022-07-02T20:26:17.725861Z",
     "iopub.status.idle": "2022-07-02T20:28:58.263059Z",
     "shell.execute_reply.started": "2022-07-02T20:26:17.725831Z",
     "shell.execute_reply": "2022-07-02T20:28:58.26135Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit([train_features_ids, \n",
    "           train_features_masks], Y_train[1000000:], \n",
    "          validation_data=([val_features_ids, \n",
    "                            val_features_masks], Y_val),\n",
    "          epochs=2, \n",
    "          batch_size=40, \n",
    "          shuffle=True,\n",
    "          callbacks=[es],\n",
    "          verbose=1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-02T20:29:06.156003Z",
     "iopub.execute_input": "2022-07-02T20:29:06.157405Z",
     "iopub.status.idle": "2022-07-03T00:37:14.006563Z",
     "shell.execute_reply.started": "2022-07-02T20:29:06.157359Z",
     "shell.execute_reply": "2022-07-03T00:37:14.005719Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.save_weights(\"bertweet_2.h5\")\n",
    "model.load_weights(\"bertweet_2.h5\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T00:37:14.008244Z",
     "iopub.execute_input": "2022-07-03T00:37:14.008602Z",
     "iopub.status.idle": "2022-07-03T00:37:15.707583Z",
     "shell.execute_reply.started": "2022-07-03T00:37:14.008567Z",
     "shell.execute_reply": "2022-07-03T00:37:15.706775Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "del train_features_ids, train_features_masks\n",
    "gc.collect()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T00:37:15.709108Z",
     "iopub.execute_input": "2022-07-03T00:37:15.709465Z",
     "iopub.status.idle": "2022-07-03T00:37:29.935965Z",
     "shell.execute_reply.started": "2022-07-03T00:37:15.709431Z",
     "shell.execute_reply": "2022-07-03T00:37:29.935188Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "test_tweets = []\n",
    "\n",
    "def load_test_tweets(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            test_tweets.append(line.rstrip())\n",
    "    \n",
    "load_test_tweets('../input/cil-twitter/twitter-datasets/test_data.txt')\n",
    "\n",
    "\n",
    "# Convert to NumPy array to facilitate indexing\n",
    "test_tweets = np.array(test_tweets)\n",
    "\n",
    "print(f'{len(test_tweets)} tweets loaded')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T08:22:54.84145Z",
     "iopub.execute_input": "2022-07-03T08:22:54.841861Z",
     "iopub.status.idle": "2022-07-03T08:22:54.8795Z",
     "shell.execute_reply.started": "2022-07-03T08:22:54.841826Z",
     "shell.execute_reply": "2022-07-03T08:22:54.878177Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_features_ids, test_features_masks = create_bert_input_features(tokenizer_tweet, test_tweets, \n",
    "                                                                    max_seq_length=MAX_SEQ_LENGTH)\n",
    "print('Test Features:', test_features_ids.shape, test_features_masks.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T08:22:58.107433Z",
     "iopub.execute_input": "2022-07-03T08:22:58.10781Z",
     "iopub.status.idle": "2022-07-03T08:23:00.34576Z",
     "shell.execute_reply.started": "2022-07-03T08:22:58.107777Z",
     "shell.execute_reply": "2022-07-03T08:23:00.344944Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#model.load_weights(\"bertweet_2.h5\")\n",
    "\n",
    "predictions = [1 if pr > 0.5 else -1 \n",
    "                   for pr in model.predict([test_features_ids, \n",
    "                                            test_features_masks], batch_size=200, verbose=0).ravel()]\n",
    "\n",
    "Id = list(range(1, 10001))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T08:23:13.648367Z",
     "iopub.execute_input": "2022-07-03T08:23:13.648727Z",
     "iopub.status.idle": "2022-07-03T08:23:38.241481Z",
     "shell.execute_reply.started": "2022-07-03T08:23:13.648695Z",
     "shell.execute_reply": "2022-07-03T08:23:38.240642Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(list(zip(Id, predictions)),\n",
    "               columns =['Id', 'Prediction'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T08:23:38.24299Z",
     "iopub.execute_input": "2022-07-03T08:23:38.243341Z",
     "iopub.status.idle": "2022-07-03T08:23:38.265703Z",
     "shell.execute_reply.started": "2022-07-03T08:23:38.243305Z",
     "shell.execute_reply": "2022-07-03T08:23:38.264791Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.to_csv('sample_submission_bertweet_3.csv',index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-03T08:23:48.903942Z",
     "iopub.execute_input": "2022-07-03T08:23:48.904412Z",
     "iopub.status.idle": "2022-07-03T08:23:48.939696Z",
     "shell.execute_reply.started": "2022-07-03T08:23:48.904373Z",
     "shell.execute_reply": "2022-07-03T08:23:48.939014Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
